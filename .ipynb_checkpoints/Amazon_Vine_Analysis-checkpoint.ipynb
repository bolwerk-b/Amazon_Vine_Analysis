{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb57ebb-e10f-402f-aa3a-d477c836882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open '$SPARK_VERSION-bin-hadoop3.tgz'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unable to find py4j in /content/spark-3.3.0-bin-hadoop3\\python, your SPARK_HOME may not be configured correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\findspark.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mpy4j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lib\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"py4j-*.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_133352\\2722169962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Start a SparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\findspark.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    161\u001b[0m             raise Exception(\n\u001b[0;32m    162\u001b[0m                 \"Unable to find py4j in {}, your SPARK_HOME may not be configured correctly\".format(\n\u001b[1;32m--> 163\u001b[1;33m                     \u001b[0mspark_python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m                 )\n\u001b[0;32m    165\u001b[0m             )\n",
      "\u001b[1;31mException\u001b[0m: Unable to find py4j in /content/spark-3.3.0-bin-hadoop3\\python, your SPARK_HOME may not be configured correctly"
     ]
    }
   ],
   "source": [
    "# Deliverable 2: Determine Bias of Vine Reviews\n",
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.3.0'\n",
    "spark_version = 'spark-3.3.0'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a764f-3f24-48c8-9621-276906b4330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrameBasics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079a5ce2-61a9-4af9-bc1d-4971ca6d16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\"\n",
    "spark.sparkContext.addFile(url)\n",
    "df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\"), sep=\"\\t\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79b204-a4b3-446f-87bf-6c93eb1a63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c4374-689b-4ac2-a83c-fa37bc4c71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a sql function to use columns\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter for only columns with total_votes equal or greater than 20\n",
    "votes20plus_df = df.filter(col(\"total_votes\") >= 20)\n",
    "votes20plus_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3dfbc-b5f1-45bd-8252-c45378f5623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes20plus_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c21d7c-72fe-4631-b448-e25bf5e8021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for helpful_votes/total_votes is >= 50%\n",
    "vote50plus_df = votes20plus_df.filter(col(\"helpful_votes\")/col(\"total_votes\") >= .50)\n",
    "vote50plus_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da663c19-50b1-4ea0-af85-40a9367cea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote50plus_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9e2f6-2398-4d00-9b4f-1bfb02ca532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for data where a review was written as part of the Vine program\n",
    "paid_vine_df = vote50plus_df.filter(col(\"vine\") == 'Y')\n",
    "paid_vine_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424675d-d128-491b-8d7e-cf9f9de305ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_vine_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f25d50-1159-4416-a39f-34890502953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for data where a review was not part of the Vine program\n",
    "unpaid_vine_df = vote50plus_df.filter(col(\"vine\") == 'N')\n",
    "unpaid_vine_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6cb87f-071b-4928-ba33-fb5eb05ede77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total # of review paid\n",
    "paid_vine_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41187a38-f222-4f8e-b6ad-f71418be07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total # of 5-star reviews paid\n",
    "paid_star_rating_df = paid_vine_df.filter(col(\"star_rating\") == 5)\n",
    "paid_star_rating_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed2ea8-822b-41a6-a835-a8994a5bcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding percentage of 5-star reviews paid\n",
    "\n",
    "# percent_paid = (paid_star_rating_df.count()/paid_vine_df.count())*100\n",
    "# print(\"Percentage of 5-star reviews for paid Vine program was: %f\" % percent_paid + \"%\")\n",
    "\n",
    "#### Unfortantly, my dataset did not have Y's in the vine column.  \n",
    "#### This code will result in a divsion by zero error. There are 0% paid Vine 5-star reviews (or any other rating level.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa16fa-325b-45dd-bb61-7529d3f4f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total # of review unpaid\n",
    "unpaid_vine_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585349c9-4faf-479e-8b61-8729f0cca72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total # of 5-star reviews unpaid\n",
    "unpaid_star_rating_df = unpaid_vine_df.filter(col(\"star_rating\") == 5)\n",
    "unpaid_star_rating_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e4eb0-1803-417d-8159-416e5660265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding percentage of 5-star reviews unpaid\n",
    "percent_unpaid = (unpaid_star_rating_df.count()/unpaid_vine_df.count())*100\n",
    "print(\"Percentage of 5-star reviews for unpaid Vine program was: %f\" % percent_unpaid + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
